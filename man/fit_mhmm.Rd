% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/fit_mhmm.R
\name{fit_mhmm}
\alias{fit_mhmm}
\title{Estimate Parameters of Mixture Hidden Markov Model}
\usage{
fit_mhmm(model, em_step = TRUE, global_step = FALSE, local_step = TRUE,
  control_em = list(), control_global = list(), control_local = list(),
  lb, ub, threads = 1, log_space = FALSE, ...)
}
\arguments{
\item{model}{Hidden Markov model of class \code{hmm}.}

\item{em_step}{Logical, use EM algorithm at the start of parameter estimation.
The default is \code{TRUE}. Note that EM algorithm is faster than direct numerical optimization,
but is even more prone to get stuck in a local optimum.}

\item{global_step}{Logical, use global optimization via
\code{\link{nloptr}} (possibly after the EM step). The default is \code{FALSE}.}

\item{local_step}{Logical, use local optimization via
\code{\link{nloptr}} (possibly after the EM and/or global steps). The default is \code{TRUE}.}

\item{control_em}{Optional list of control parameters for for EM algorithm.
Possible arguments are \describe{
\item{maxeval}{Maximum number of iterations, default is 100.}
\item{print_level}{Level of printing. Possible values are 0
(prints nothing), 1 (prints information at start and end of algorithm), and
2 (prints at every iteration).}
\item{reltol}{Relative tolerance for convergence defined as \eqn{(logLik_new - logLik_old)/(abs(logLik_old)+0.1)}.
Default is 1e-8.}
\item{restarts}{Number of restarts of EM algorithm using random initial values. Default is 0. }
\item{restart_transition}{Logical, should the initial transition
probabilities be varied. Default is \code{TRUE}. }
\item{restart_emission}{Logical, should the initial emission
probabilities be varied. Default is \code{TRUE}. }
\item{sd_restart}{Standard deviation for \code{rnorm} used in restarting. Default is 0.25.} }}

\item{control_global}{Optional list of additional arguments for
  \code{\link{nloptr}} argument \code{opts}. The default values are
  \describe{
   \item{algorithm}{\code{"NLOPT_GD_MLSL_LDS"}}
   \item{local_opts}{\code{list(algorithm = "NLOPT_LD_LBFGS",  xtol_rel = 1e-4)}}
   \item{maxeval}{\code{10000} (maximum number of iterations in global optimization algorithm)}
}}

\item{control_local}{Optional list of additional arguments for
\code{\link{nloptr}} argument \code{opts}. The default values are
\describe{
 \item{algorithm}{\code{"NLOPT_LD_LBFGS"}}
 \item{xtol_rel}{\code{1e-8}}
 \item{maxeval}{\code{10000} (maximum number of iterations)}
}}

\item{lb}{Lower and upper bounds for parameters in Softmax parameterization.
Default interval is [pmin(-10,2*initialvalues), pmax(10,2*initialvalues)].
Used only in the global optimization step.}

\item{ub}{Lower and upper bounds for parameters in Softmax parameterization.
Default interval is [pmin(-10,2*initialvalues), pmax(10,2*initialvalues)].
Used only in the global optimization step.}

\item{threads}{Number of threads to use in parallel computing. Default is 1.}

\item{log_space}{Make computations using log-space instead of scaling for greater
numerical stability at cost of computational costs. Default is \code{FALSE}.}

\item{...}{Additional arguments to nloptr}
}
\value{
List with components \item{model}{Estimated model. }
  \item{logLik}{Log-likelihood of the estimated model. }
  \item{em_results}{Results after the EM step. }
  \item{global_results}{Results after the global step. }
  \item{local_results}{Results after the local step. }
}
\description{
Function \code{fit_mhmm} estimates a mixture of hidden Markov models
using numerical maximization of log-likelihood. Initial values for estimation
are taken from the corresponding components of the model with preservation of
original zero probabilities.
}
\details{
The fitting function provides three estimation steps: 1) EM algorithm,
  2) global optimization, and 3) local optimization. The user can call for one method
  or any combination of these steps, but should note that they are preformed in the
  above-mentioned order. The results from a former step are used as starting values
  in a latter.

  By default the \code{fit_mhmm} function starts with the EM algorithm,
  and finishes with LBFGS as the local optimizer.

  It is possible to rerun EM algorithm automatically using random starting
  values based on the first run of EM. Number of restarts is defined by
  argument \code{restarts} in \code{control_em}. As EM algorithm is relatively fast, this method
  might be preferred option compared to proper global optimization strategy of step 2.

  Default global optimization method (triggered via \code{global_step = TRUE} is
  the multilevel single-linkage method (MLSL) with the LDS modification (\code{NLOPT_GD_MLSL_LDS} as
  \code{algorithm} in \code{control_global}), with LBFGS as the local optimizer.
  The MLSL method draws random starting points and performs a local optimization
  from each. The LDS modification uses low-discrepancy sequences instead of
  pseudo-random numbers as starting points and should improve the convergence rate.
  In order to reduce the computation time spent on non-global optima, the
  convergence tolerance of the local optimizer is set relatively large. At step 3,
  a local optimization (LBFGS by default) is run with a lower tolerance to find the
  optimum with high precision.

  There are some theoretical guarantees that the MLSL method used as the default
  optimizer in step 2 shoud find all local optima in a finite number of local
  optimizations. Of course, it might not always succeed in a reasonable time.
  The EM algorithm can help in finding good boundaries for the search, especially
  with good starting values, but in some cases it can mislead. A good strategy is to
  try a couple of different fitting options with different combinations of the methods:
  e.g. all steps, only global and local steps, and a few evaluations of EM followed by
  global and local optimization.

  By default, the estimation time is limited to 60 seconds in global optimization step, so it is
  advisable to change the default settings for the proper global optimization.

  Any method available in the \code{nloptr} function can be used for the global and
  local steps.
}
\examples{
# Single-channel

data(mvad, package = "TraMineR")

mvad.alphabet <- c("employment", "FE", "HE", "joblessness", "school",
                   "training")
mvad.labels <- c("employment", "further education", "higher education",
                 "joblessness", "school", "training")
mvad.scodes <- c("EM", "FE", "HE", "JL", "SC", "TR")
mvad.seq <- seqdef(mvad, 17:86, alphabet = mvad.alphabet, states = mvad.scodes,
                   labels = mvad.labels, xtstep = 6)

# Starting values for emission matrices
emiss_1 <- matrix(
c(0.26, 0.39, 0.01, 0.06, 0.04, 0.24,
  0.58, 0.12, 0.09, 0.10, 0.01, 0.10,
  0.73, 0.02, 0.09, 0.13, 0.01, 0.02),
nrow = 3, ncol = 6, byrow = TRUE)

emiss_2 <- matrix(
c(0.01, 0.02, 0.01, 0.01, 0.94, 0.01,
  0.05, 0.06, 0.15, 0.01, 0.72, 0.01,
  0.19, 0.13, 0.60, 0.01, 0.05, 0.02,
  0.32, 0.03, 0.60, 0.03, 0.01, 0.01),
nrow = 4, ncol = 6, byrow = TRUE)

# Starting values for transition matrices

tr_1 <-  matrix(
  c(0.80, 0.10, 0.10,
    0.10, 0.80, 0.10,
    0.10, 0.10, 0.80),
  nrow=3, ncol=3, byrow=TRUE)

tr_2 <-  matrix(
  c(0.80, 0.10, 0.05, 0.05,
    0.05, 0.80, 0.10, 0.05,
    0.05, 0.05, 0.80, 0.10,
    0.05, 0.05, 0.10, 0.80),
  nrow=4, ncol=4, byrow=TRUE)

# Starting values for initial state probabilities
init_1 <- c(0.4, 0.3, 0.3)
init_2 <- c(0.3, 0.3, 0.2, 0.2)

# Building a MHMM with the starting values
init_mhmm_mvad <- build_mhmm(
  observations = mvad.seq,
  transition_probs = list(tr_1, tr_2),
  emission_probs = list(emiss_1, emiss_2),
  initial_probs = list(init_1, init_2))

# Fitting the model with the EM algorithm
fit_mvad <- fit_mhmm(
  init_mhmm_mvad, local_step = FALSE)
fit_mvad$logLik # -20639.1
\dontrun{
# Run EM algorithm 25 times with simulated starting values
set.seed(321)
fit_mvad2 <- fit_mhmm(init_mhmm_mvad, control_em=list(restarts = 25))
fit_mvad2$logLik # -14651.43
}
##############################################################

# Multichannel

data(biofam3c)

# Building sequence objects
child.seq <- seqdef(biofam3c$children)
marr.seq <- seqdef(biofam3c$married)
left.seq <- seqdef(biofam3c$left)

## Starting values for emission probabilities

# Cluster 1
alphabet(child.seq) # Checking for the order of observed states
emiss_1_child <- matrix(
  c(0.99, 0.01, # High probability for childless
    0.99, 0.01,
    0.99, 0.01,
    0.99, 0.01),
  nrow = 4, ncol = 2, byrow = TRUE)

alphabet(marr.seq)
emiss_1_marr <- matrix(
  c(0.01, 0.01, 0.98, # High probability for single
    0.01, 0.01, 0.98,
    0.01, 0.98, 0.01, # High probability for married
    0.98, 0.01, 0.01), # High probability for divorced
  nrow = 4, ncol = 3, byrow = TRUE)

alphabet(left.seq)
emiss_1_left <- matrix(
  c(0.01, 0.99, # High probability for living with parents
    0.99, 0.01, # High probability for having left home
    0.99, 0.01,
    0.99, 0.01),
  nrow = 4, ncol = 2, byrow = TRUE)

# Cluster 2
emiss_2_child <- matrix(
  c(0.99, 0.01, # High probability for childless
    0.99, 0.01,
    0.99, 0.01,
    0.01, 0.99),
  nrow = 4, ncol = 2, byrow = TRUE)

emiss_2_marr <- matrix(
  c(0.01, 0.01, 0.98, # High probability for single
    0.01, 0.01, 0.98,
    0.01, 0.98, 0.01, # High probability for married
    0.29, 0.7, 0.01),
  nrow = 4, ncol = 3, byrow = TRUE)

emiss_2_left <- matrix(
  c(0.01, 0.99, # High probability for living with parents
    0.99, 0.01,
    0.99, 0.01,
    0.99, 0.01),
  nrow = 4, ncol = 2, byrow = TRUE)

# Cluster 3
emiss_3_child <- matrix(
  c(0.99, 0.01, # High probability for childless
    0.99, 0.01,
    0.01, 0.99,
    0.99, 0.01,
    0.01, 0.99,
    0.01, 0.99),
  nrow = 6, ncol = 2, byrow = TRUE)

emiss_3_marr <- matrix(
  c(0.01, 0.01, 0.98, # High probability for single
    0.01, 0.01, 0.98,
    0.01, 0.01, 0.98,
    0.01, 0.98, 0.01,
    0.01, 0.98, 0.01, # High probability for married
    0.98, 0.01, 0.01), # High probability for divorced
  nrow = 6, ncol = 3, byrow = TRUE)

emiss_3_left <- matrix(
  c(0.01, 0.99, # High probability for living with parents
    0.99, 0.01,
    0.50, 0.50,
    0.01, 0.99,
    0.99, 0.01,
    0.99, 0.01),
  nrow = 6, ncol = 2, byrow = TRUE)

# Initial values for transition matrices
trans_1 <- matrix(
  c(0.80,   0.16, 0.03, 0.01,
       0,   0.90, 0.07, 0.03,
       0,      0, 0.90, 0.10,
       0,      0,    0,    1),
  nrow = 4, ncol = 4, byrow = TRUE)

trans_2 <- matrix(
  c(0.80, 0.10, 0.05,  0.03, 0.01, 0.01,
       0, 0.70, 0.10,  0.10, 0.05, 0.05,
       0,    0, 0.85,  0.01, 0.10, 0.04,
       0,    0,    0,  0.90, 0.05, 0.05,
       0,    0,    0,     0, 0.90, 0.10,
       0,    0,    0,     0,    0,    1),
  nrow = 6, ncol = 6, byrow = TRUE)

# Initial values for initial state probabilities
initial_probs1 <- c(0.9, 0.07, 0.02, 0.01)
initial_probs2 <- c(0.9, 0.04, 0.03, 0.01, 0.01, 0.01)

# Birth cohort
biofam3c$covariates$cohort <- cut(biofam3c$covariates$birthyr, c(1908, 1935, 1945, 1957))
biofam3c$covariates$cohort <- factor(
  biofam3c$covariates$cohort, labels=c("1909-1935", "1936-1945", "1946-1957"))

# Build mixture HMM
init_mhmm_bf <- build_mhmm(
  observations = list(child.seq, marr.seq, left.seq),
  transition_probs = list(trans_1, trans_1, trans_2),
  emission_probs = list(list(emiss_1_child, emiss_1_marr, emiss_1_left),
                        list(emiss_2_child, emiss_2_marr, emiss_2_left),
                        list(emiss_3_child, emiss_3_marr, emiss_3_left)),
  initial_probs = list(initial_probs1, initial_probs1, initial_probs2),
  formula = ~sex + cohort, data = biofam3c$covariates,
  cluster_names = c("Cluster 1", "Cluster 2", "Cluster 3"),
  channel_names = c("Parenthood", "Marriage", "Left home"))

# Fitting the model with different settings

# Only EM with default values
mhmm_1 <- fit_mhmm(
  init_mhmm_bf, em_step = TRUE, global_step = FALSE, local_step = FALSE)
mhmm_1$logLik # -3081.383

\dontrun{
# EM with LBFGS
mhmm_2 <- fit_mhmm(
  init_mhmm_bf, em_step = TRUE, global_step = FALSE, local_step = TRUE)
mhmm_2$logLik # -3081.383

# Only LBFGS
mhmm_3 <- fit_mhmm(
  init_mhmm_bf, em_step = FALSE, global_step = FALSE, local_step = TRUE,
  control_local = list(maxeval = 5000, maxtime = 0))
mhmm_3$logLik # -3087.499373

# Global optimization via MLSL_LDS with LBFGS as local optimizer and final polisher
mhmm_4 <- fit_mhmm(
  init_mhmm_bf, em_step = FALSE, global_step = TRUE, local_step = TRUE,
  control_global = list(maxeval = 5000, maxtime = 0))
mhmm_4$logLik # -3150.796

# As previously, but now we use ten iterations from EM algorithm for
# defining initial values and boundaries
# Note smaller maxeval for global optimization
mhmm_5 <- fit_mhmm(
  init_mhmm_bf, em_step = TRUE, global_step = TRUE, local_step = TRUE,
  control_em = list(maxeval = 10), control_global = list(maxeval = 1000, maxtime = 0),
  control_local = list(maxeval = 500, maxtime = 0))
mhmm_5$logLik #-3081.383
}
}
\seealso{
\code{\link{build_mhmm}} for building MHMMs; \code{\link{summary.mhmm}}
  for a summary of a MHMM; \code{\link{separate_mhmm}} for reorganizing a MHMM into
  a list of separate hidden Markov models;
  \code{\link{build_hmm}} and \code{\link{fit_hmm}} for building and
  fitting hidden Markov models; \code{\link{plot.mhmm}}
  for plotting \code{mhmm} objects; and \code{\link{mssplot}} for plotting
  stacked sequence plots of \code{mhmm} objects.
}

